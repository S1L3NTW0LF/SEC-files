{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af42a49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f78465c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86e2591e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05e2cac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_files = pd.Series(os.listdir('companyfacts/'))\n",
    "list_sub = pd.Series(os.listdir('submissions/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db2c3943",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stock = pd.DataFrame()\n",
    "KeyError_list = pd.Series()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c794fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r KeyError_list\n",
    "%store -r df_stock\n",
    "%store -r tracker "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c99f4760",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc4631cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.910151469160194\n",
      "73.72748851776123\n",
      "16.676799671069997\n",
      "29.05796813426045\n",
      "KEYERROR:\t\t\tCIK0001473845.json\n",
      "25.549875803230222\n",
      "34.845667019353215\n",
      "40.13304329380285\n",
      "41.93393119068103\n",
      "25.87323172939972\n",
      "37.57267412932023\n",
      "59.46067663339468\n",
      "41.660148275485646\n",
      "71.82485057461646\n",
      "33.86021710702501\n",
      "KEYERROR:\t\t\tCIK0001834048.json\n",
      "25.716206258978726\n",
      "39.54348501644286\n",
      "24.58013915509361\n",
      "KEYERROR:\t\t\tCIK0001116284.json\n",
      "KEYERROR:\t\t\tCIK0001264279.json\n",
      "KEYERROR:\t\t\tCIK0001559771.json\n",
      "41.402779720925\n",
      "42.98326103411453\n",
      "31.38646999892895\n",
      "KEYERROR:\t\t\tCIK0000313216.json\n",
      "44.01628548900287\n",
      "36.86277298909712\n",
      "68.20293120395989\n",
      "42.47472832268501\n",
      "35.09918027955502\n",
      "KEYERROR:\t\t\tCIK0001840821.json\n",
      "78.73741063204679\n",
      "KEYERROR:\t\t\tCIK0000768609.json\n",
      "69.88488965564304\n",
      "51.778923897516165\n",
      "23.031884548710842\n",
      "30.921336718628236\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[38;5;28;01mmatch\u001b[39;00m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfn_name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m yy\n\u001b[1;32m     57\u001b[0m                 \u001b[38;5;28;01mmatch\u001b[39;00m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcik\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data_comp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcik\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 59\u001b[0m                 df_stock \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf_stock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     61\u001b[0m                 ttt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m#                 match.to_csv('100.csv', mode='a', header=False, index=False)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/concat.py:360\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03mConcatenate pandas objects along a particular axis with optional set logic\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;124;03malong the other axes.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;124;03mValueError: Indexes have overlapping values: ['a']\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    347\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[1;32m    348\u001b[0m     objs,\n\u001b[1;32m    349\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m    358\u001b[0m )\n\u001b[0;32m--> 360\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/concat.py:595\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    591\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m obj_labels\u001b[38;5;241m.\u001b[39mget_indexer(new_labels)\n\u001b[1;32m    593\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[0;32m--> 595\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[43mconcatenate_managers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmgrs_indexers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_axes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcat_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbm_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy:\n\u001b[1;32m    599\u001b[0m     new_data\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/internals/concat.py:213\u001b[0m, in \u001b[0;36mconcatenate_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m    210\u001b[0m concat_plan \u001b[38;5;241m=\u001b[39m _combine_concat_plans(concat_plans)\n\u001b[1;32m    211\u001b[0m blocks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 213\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m placement, join_units \u001b[38;5;129;01min\u001b[39;00m concat_plan:\n\u001b[1;32m    214\u001b[0m     unit \u001b[38;5;241m=\u001b[39m join_units[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    215\u001b[0m     blk \u001b[38;5;241m=\u001b[39m unit\u001b[38;5;241m.\u001b[39mblock\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/internals/concat.py:650\u001b[0m, in \u001b[0;36m_combine_concat_plans\u001b[0;34m(plans)\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    649\u001b[0m         yielded_placement \u001b[38;5;241m=\u001b[39m plc\n\u001b[0;32m--> 650\u001b[0m         next_items[i] \u001b[38;5;241m=\u001b[39m \u001b[43m_next_or_none\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplans\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m yielded_placement, yielded_units\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for x, y in enumerate(list_files[:500]):\n",
    "    df_stock = pd.DataFrame()\n",
    "    \n",
    "    # Block of code opens two json files and then creates AccessionNumber List \n",
    "#     print(f'{x}   {y}')\n",
    "    \n",
    "    with open(f'companyfacts/{y}') as datafile:\n",
    "        data_comp = json.load(datafile)\n",
    "        \n",
    "    with open(f'submissions/{y}') as datafile:\n",
    "        data_sub = json.load(datafile)\n",
    "    \n",
    "    df_submissions = pd.DataFrame(data_sub['filings']['recent'])\n",
    "    df_10K = df_submissions.loc[df_submissions['form'] == '10-K']\n",
    "\n",
    "    accn_list = df_10K['accessionNumber']\n",
    "    accn_list = accn_list.reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    # Block of code adds AccessionNumbers from additional json submission files \n",
    "    CIK_num = y[:-5]\n",
    "    pattern = re.compile(f'{CIK_num}-submissions')\n",
    "\n",
    "    for i in list_sub:\n",
    "        matches = pattern.findall(i)\n",
    "        \n",
    "        for match in matches:\n",
    "            \n",
    "            with open(f'submissions/{i}') as datafile:\n",
    "                data_sub = json.load(datafile)\n",
    "         \n",
    "            df_submissions = pd.DataFrame(data_sub)\n",
    "            df_10K = df_submissions.loc[df_submissions['form'] == '10-K']\n",
    "\n",
    "            accn_additions = df_10K['accessionNumber']\n",
    "            accn_additions = accn_additions.reset_index(drop=True)\n",
    "            \n",
    "            accn_list = pd.concat([accn_list, accn_additions], ignore_index=True)\n",
    "            \n",
    "    ttt = 0 \n",
    "    st = time.time()\n",
    "    # Block of code pulls appropriate data from json file and then concatenates to data fram\n",
    "    try: \n",
    "        for xx, yy in enumerate(data_comp['facts']['us-gaap']):\n",
    "        \n",
    "            df = data_comp['facts']['us-gaap'][yy]['units']\n",
    "\n",
    "            units = pd.Series(df.keys()).iloc[0]\n",
    "\n",
    "            df = pd.DataFrame(data_comp['facts']['us-gaap'][yy]['units'][units])\n",
    "            \n",
    "            \n",
    "            for ii in accn_list:\n",
    "                match = df.loc[df['accn'] == ii]\n",
    "\n",
    "                match['fn_name'] = yy\n",
    "                match['cik'] = data_comp['cik']\n",
    "                                    \n",
    "                \n",
    "                ttt += 1\n",
    "                \n",
    "                match.to_csv('100.csv', mode='a', header=False, index=False)\n",
    "        \n",
    "    \n",
    "        df_stock.to_csv('500.csv', mode='a', header=False, index=False)\n",
    "        \n",
    "        et = time.time()\n",
    "        elap = et - st \n",
    "        \n",
    "        if ttt != 0:\n",
    "            print(elap / ttt * 10000)\n",
    "        \n",
    "    except KeyError:\n",
    "                print(f\"KEYERROR:\\t\\t\\t{y}\")\n",
    "                KeyError_list = pd.concat([KeyError_list, pd.Series(y)])\n",
    "                \n",
    "                tracker += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2015e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stock.to_csv('331_files.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed0d93be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'df_stock' (DataFrame)\n",
      "Stored 'KeyError_list' (Series)\n"
     ]
    }
   ],
   "source": [
    "%store df_stock\n",
    "%store KeyError_list\n",
    "%store tracker"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
